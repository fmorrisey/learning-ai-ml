{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efd6bb63",
   "metadata": {},
   "source": [
    "# 08 — Debugging Shapes & Common Errors\n",
    "**Goal:** make shape/typing errors boring. We’ll trigger the most common mistakes on purpose and fix them.\n",
    "\n",
    "**Covers:**\n",
    "- Reading PyTorch error messages\n",
    "- Batch dimension vs feature dimension\n",
    "- Wrong target dtype for `CrossEntropyLoss`\n",
    "- Channel-first images (C×H×W) vs channel-last (H×W×C)\n",
    "- Device mismatch (CPU vs CUDA)\n",
    "- Gradients accumulating & forgetting `model.eval()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f257d3c0",
   "metadata": {},
   "source": [
    "## 0) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8daf88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device:', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0167d0",
   "metadata": {},
   "source": [
    "## 1) Batch vs feature dims\n",
    "**Rule of thumb:** most dense layers expect shape `[batch, features]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128fbe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(32, 16)\n",
    "bad_x = torch.randn(16, 32)\n",
    "linear = nn.Linear(16, 4)\n",
    "print('good:', linear(x).shape)\n",
    "try:\n",
    "    linear(bad_x)\n",
    "except Exception as e:\n",
    "    print('bad shape error ->', type(e).__name__, e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1face2d",
   "metadata": {},
   "source": [
    "## 2) CrossEntropyLoss target dtype\n",
    "`CrossEntropyLoss` expects **class indices** (LongTensor), **not one-hot** floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bff66f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.randn(8, 10)\n",
    "y_ok = torch.randint(0, 10, (8,))\n",
    "y_bad = F.one_hot(y_ok, 10).float()\n",
    "ce = nn.CrossEntropyLoss()\n",
    "print('ok:', ce(logits, y_ok).item())\n",
    "try:\n",
    "    ce(logits, y_bad)\n",
    "except Exception as e:\n",
    "    print('wrong target error ->', type(e).__name__, e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4788c0b5",
   "metadata": {},
   "source": [
    "## 3) Images are channel-first (C×H×W) in PyTorch\n",
    "**Transform fix:** `permute(2,0,1)` turns H×W×C into C×H×W."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9997476",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_hwc = torch.randn(64, 64, 3)\n",
    "try:\n",
    "    nn.Conv2d(3, 8, 3)(img_hwc)\n",
    "except Exception as e:\n",
    "    print('conv expects NCHW ->', type(e).__name__, e)\n",
    "img_chw = img_hwc.permute(2,0,1)\n",
    "img_nchw = img_chw.unsqueeze(0)\n",
    "print('fixed:', nn.Conv2d(3, 8, 3)(img_nchw).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e337f58b",
   "metadata": {},
   "source": [
    "## 4) Device mismatch (CPU vs GPU)\n",
    "Move **both** model and data to the same device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6e1074",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Linear(16, 4).to(device)\n",
    "x_cpu = torch.randn(2,16)\n",
    "try:\n",
    "    m(x_cpu)\n",
    "except Exception as e:\n",
    "    print('device mismatch ->', type(e).__name__, e)\n",
    "x_dev = x_cpu.to(device)\n",
    "print('fixed:', m(x_dev).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3001ecc2",
   "metadata": {},
   "source": [
    "## 5) Accumulating grads & train/eval modes\n",
    "Gradients **accumulate** by default; clear them each step. Use `model.eval()` during validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a7f3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Linear(8,1).to(device)\n",
    "opt = torch.optim.SGD(m.parameters(), lr=0.1)\n",
    "x = torch.randn(4,8, device=device)\n",
    "y = torch.randn(4,1, device=device)\n",
    "loss_fn = nn.MSELoss()\n",
    "for step in range(3):\n",
    "    pred = m(x)\n",
    "    loss = loss_fn(pred, y)\n",
    "    loss.backward()\n",
    "    # opt.zero_grad()  # (commented to show accumulation)\n",
    "    opt.step()\n",
    "    print(f'step {step} ok but grads accumulate!')\n",
    "print('Fix by calling opt.zero_grad() before backward and step.')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}